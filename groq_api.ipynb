{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d871f914-5b64-4b23-8568-152369c74921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first person to land on the moon was Neil Armstrong. He stepped out of the lunar module Eagle and onto the moon's surface on July 20, 1969, during the Apollo 11 mission. Armstrong famously declared, \"That's one small step for man, one giant leap for mankind,\" as he became the first human to set foot on the moon.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='', \n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"The first person to land on moon was ...\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00ed6f1c-0bff-44d2-b657-e0c65511bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05ebdf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is about New Delhi\",\n",
    "        \"This is about New York\"\n",
    "    ],\n",
    "    ids = [\"id5\",\"id6\"],\n",
    "    metadatas = [\n",
    "        {\"url\" : \"https://www.newdelhi.com/\"},\n",
    "        {\"url\" : \"https://www.newyork.com/\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1cf7733-a6bd-4781-9d3f-1c6c4bd834cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1', 'id2', 'id3', 'id4', 'id5', 'id6'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['This is about New Delhi',\n",
       "  'This is about New York',\n",
       "  'This document is about New York',\n",
       "  'This document is about Delhi',\n",
       "  'This is about New Delhi',\n",
       "  'This is about New York'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None,\n",
       "  None,\n",
       "  {'url': 'https://en.wikipedia.org/wiki/New_York_City'},\n",
       "  {'url': 'https://en.wikipedia.org/wiki/New_Delhi'},\n",
       "  {'url': 'https://www.newdelhi.com/'},\n",
       "  {'url': 'https://www.newyork.com/'}]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=collection.get()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "753b3e8a-9389-4953-ad5d-869c68c64c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['This is about New Delhi'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=collection.get(ids=[\"id1\"])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8055591f-a94e-460f-9f05-7627100bae92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id1', 'id5']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is about New Delhi', 'This is about New Delhi']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, {'url': 'https://www.newdelhi.com/'}]],\n",
       " 'distances': [[1.478261113166809, 1.478261113166809]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"I want to eat pani puri\"],\n",
    "    n_results=2\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08c0b989-8f90-4ec6-9a41-2f814a0ddc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete(ids=\"ids1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "661a3251-aad3-47d2-b70f-0e8b5dbcaf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1', 'id2', 'id3', 'id4', 'id5', 'id6'],\n",
       " 'embeddings': None,\n",
       " 'documents': ['This is about New Delhi',\n",
       "  'This is about New York',\n",
       "  'This document is about New York',\n",
       "  'This document is about Delhi',\n",
       "  'This is about New Delhi',\n",
       "  'This is about New York'],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None,\n",
       "  None,\n",
       "  {'url': 'https://en.wikipedia.org/wiki/New_York_City'},\n",
       "  {'url': 'https://en.wikipedia.org/wiki/New_Delhi'},\n",
       "  {'url': 'https://www.newdelhi.com/'},\n",
       "  {'url': 'https://www.newyork.com/'}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba58c4c3-1864-4c13-95ad-c160227fc603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.stepstone.de/stellenangebote--Product-Owner-Product-Data-Management-and-Presentation-m-f-d-Muenchen-Jochen-Schweizer-mydays-Holding-GmbH--12317502-inline.html?rltr=1_1_25_seorl_m_0_0_0_0_1_0\")\n",
    "page_data = loader.load().pop().page_content\n",
    "print(type(page_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679e8d2-8370-4dbb-9e2c-18131d847791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e04e7a59-5381-4fac-a3a9-29a0a7130626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"role\": \"Product Owner: Product Data Management and Presentation\",\\n  \"experience\": \"More than 3 years of experience in a Product role coming from a value- and customer-driven environment\",\\n  \"skills\": [\\n    \"Effective in communication, planning and good coordination skills\",\\n    \"Good knowledge and proven experience in working with software development teams, preferably in agile frameworks like Scrum or Kanban\",\\n    \"Fluent business communication in English. Ability to communicate in German is a plus but not required\"\\n  ],\\n  \"employment_type\": \"Full-time\",\\n  \"location\": \"Munich, Germany\",\\n  \"description\": \"Join our vibrant team at JSMD, a proud member of the ProSiebenSat.1 Group, where we bring people together through unforgettable real-life experiences. As our Product Owner: Product Data Management and Presentation, you will play a crucial role in enhancing our digital product offerings. Your ability to manage and present product data will help us deliver impactful experiences to our customers.\",\\n  \"responsibilities\": [\\n    \"Own and optimize product data flows, including tools and services that empower internal stakeholders to efficiently manage our product portfolio\",\\n    \"Understand our products and customers to continuously refine Product Detail Pages (PDPs) and ensure they are informative and inspiring while driving engagement and supporting key KPIs\",\\n    \"Enable our Search & Filtering Team with the right product data to improve discoverability of our products and help customers easily find the experiences they seek\",\\n    \"Collaborate with analysts, the UX/UI team, and stakeholders to turn key ideas into a prioritized, actionable, KPI-driven roadmap that delivers customer and business value\"\\n  ],\\n  \"tools\": [\\n    \"Google Analytics 4\",\\n    \"Looker Studio\",\\n    \"Power BI\",\\n    \"Usercentrics\",\\n    \"JIRA\",\\n    \"Confluence\",\\n    \"Miro\",\\n    \"ClickUp\",\\n    \"Slack\",\\n    \"MS365\",\\n    \"Figma\",\\n    \"Overflow\"\\n  ],\\n  \"tech_stack\": {\\n    \"frontend\": [\\n      \"React\",\\n      \"TypeScript\",\\n      \"Node.js (Fastify)\",\\n      \"Jest\",\\n      \"React Testing Library\"\\n    ],\\n    \"backend\": [\\n      \"NestJS\",\\n      \"PHP\",\\n      \"PostgreSQL\",\\n      \"Apache Kafka\",\\n      \"AWS (Lambda@Edge, CloudFront)\"\\n    ],\\n    \"infrastructure\": [\\n      \"Docker\",\\n      \"Kubernetes\",\\n      \"AWS\",\\n      \"Terraform\",\\n      \"Helm\",\\n      \"Istio\",\\n      \"Datadog\",\\n      \"CloudWatch\"\\n    ]\\n  },\\n  \"company\": \"Jochen Schweizer mydays Holding GmbH\",\\n  \"industry\": \"Leisure, Tourism, Culture & Sport\"\\n}\\n```'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='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', \n",
    "    model_name=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website which has the job posting details.\n",
    "        Your job is to extract the job postings and return them in JSON format containing all the necessary information including the\n",
    "        following keys: `role`, `experience`, `skills` , `employment type`, `location`  and `description` . Please add other keys if founds in the document and translate\n",
    "        the text to english from any language received.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e2b0875c-f447-4103-a4f2-1f33096e7ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n  \"role\": \"Product Owner: Product Data Management and Presentation\",\\n  \"experience\": \"More than 3 years of experience in a Product role coming from a value- and customer-driven environment\",\\n  \"skills\": [\\n    \"Effective in communication, planning and good coordination skills\",\\n    \"Good knowledge and proven experience in working with software development teams, preferably in agile frameworks like Scrum or Kanban\",\\n    \"Fluent business communication in English. Ability to communicate in German is a plus but not required\"\\n  ],\\n  \"employment_type\": \"Full-time\",\\n  \"location\": \"Munich, Germany\",\\n  \"description\": \"Join our vibrant team at JSMD, a proud member of the ProSiebenSat.1 Group, where we bring people together through unforgettable real-life experiences. As our Product Owner: Product Data Management and Presentation, you will play a crucial role in enhancing our digital product offerings. Your ability to manage and present product data will help us deliver impactful experiences to our customers.\",\\n  \"responsibilities\": [\\n    \"Own and optimize product data flows, including tools and services that empower internal stakeholders to efficiently manage our product portfolio\",\\n    \"Understand our products and customers to continuously refine Product Detail Pages (PDPs) and ensure they are informative and inspiring while driving engagement and supporting key KPIs\",\\n    \"Enable our Search & Filtering Team with the right product data to improve discoverability of our products and help customers easily find the experiences they seek\",\\n    \"Collaborate with analysts, the UX/UI team, and stakeholders to turn key ideas into a prioritized, actionable, KPI-driven roadmap that delivers customer and business value\"\\n  ],\\n  \"tools\": [\\n    \"Google Analytics 4\",\\n    \"Looker Studio\",\\n    \"Power BI\",\\n    \"Usercentrics\",\\n    \"JIRA\",\\n    \"Confluence\",\\n    \"Miro\",\\n    \"ClickUp\",\\n    \"Slack\",\\n    \"MS365\",\\n    \"Figma\",\\n    \"Overflow\"\\n  ],\\n  \"tech_stack\": {\\n    \"frontend\": [\\n      \"React\",\\n      \"TypeScript\",\\n      \"Node.js (Fastify)\",\\n      \"Jest\",\\n      \"React Testing Library\"\\n    ],\\n    \"backend\": [\\n      \"NestJS\",\\n      \"PHP\",\\n      \"PostgreSQL\",\\n      \"Apache Kafka\",\\n      \"AWS (Lambda@Edge, CloudFront)\"\\n    ],\\n    \"infrastructure\": [\\n      \"Docker\",\\n      \"Kubernetes\",\\n      \"AWS\",\\n      \"Terraform\",\\n      \"Helm\",\\n      \"Istio\",\\n      \"Datadog\",\\n      \"CloudWatch\"\\n    ]\\n  },\\n  \"company\": \"Jochen Schweizer mydays Holding GmbH\",\\n  \"industry\": \"Leisure, Tourism, Culture & Sport\"\\n}\\n```'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5de43b5-d4df-43f4-8013-3359bfde28db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Product Owner: Product Data Management and Presentation',\n",
       " 'experience': 'More than 3 years of experience in a Product role coming from a value- and customer-driven environment',\n",
       " 'skills': ['Effective in communication, planning and good coordination skills',\n",
       "  'Good knowledge and proven experience in working with software development teams, preferably in agile frameworks like Scrum or Kanban',\n",
       "  'Fluent business communication in English. Ability to communicate in German is a plus but not required'],\n",
       " 'employment_type': 'Full-time',\n",
       " 'location': 'Munich, Germany',\n",
       " 'description': 'Join our vibrant team at JSMD, a proud member of the ProSiebenSat.1 Group, where we bring people together through unforgettable real-life experiences. As our Product Owner: Product Data Management and Presentation, you will play a crucial role in enhancing our digital product offerings. Your ability to manage and present product data will help us deliver impactful experiences to our customers.',\n",
       " 'responsibilities': ['Own and optimize product data flows, including tools and services that empower internal stakeholders to efficiently manage our product portfolio',\n",
       "  'Understand our products and customers to continuously refine Product Detail Pages (PDPs) and ensure they are informative and inspiring while driving engagement and supporting key KPIs',\n",
       "  'Enable our Search & Filtering Team with the right product data to improve discoverability of our products and help customers easily find the experiences they seek',\n",
       "  'Collaborate with analysts, the UX/UI team, and stakeholders to turn key ideas into a prioritized, actionable, KPI-driven roadmap that delivers customer and business value'],\n",
       " 'tools': ['Google Analytics 4',\n",
       "  'Looker Studio',\n",
       "  'Power BI',\n",
       "  'Usercentrics',\n",
       "  'JIRA',\n",
       "  'Confluence',\n",
       "  'Miro',\n",
       "  'ClickUp',\n",
       "  'Slack',\n",
       "  'MS365',\n",
       "  'Figma',\n",
       "  'Overflow'],\n",
       " 'tech_stack': {'frontend': ['React',\n",
       "   'TypeScript',\n",
       "   'Node.js (Fastify)',\n",
       "   'Jest',\n",
       "   'React Testing Library'],\n",
       "  'backend': ['NestJS',\n",
       "   'PHP',\n",
       "   'PostgreSQL',\n",
       "   'Apache Kafka',\n",
       "   'AWS (Lambda@Edge, CloudFront)'],\n",
       "  'infrastructure': ['Docker',\n",
       "   'Kubernetes',\n",
       "   'AWS',\n",
       "   'Terraform',\n",
       "   'Helm',\n",
       "   'Istio',\n",
       "   'Datadog',\n",
       "   'CloudWatch']},\n",
       " 'company': 'Jochen Schweizer mydays Holding GmbH',\n",
       " 'industry': 'Leisure, Tourism, Culture & Sport'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4ad30de-e1d5-4b0d-9fe7-2e078ee27daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Acer\n",
      " Volume Serial Number is EE7D-8C3E\n",
      "\n",
      " Directory of C:\\Users\\indus\\Documents\\Python Project\\Cover_letter_generator\n",
      "\n",
      "04/06/2025  09:38 PM    <DIR>          .\n",
      "04/04/2025  05:41 PM    <DIR>          ..\n",
      "04/06/2025  03:24 PM             3,298 .gitignore\n",
      "04/04/2025  06:24 PM    <DIR>          .ipynb_checkpoints\n",
      "04/06/2025  06:28 PM    <DIR>          .vscode\n",
      "04/06/2025  05:10 PM    <DIR>          apps\n",
      "04/04/2025  06:01 PM    <DIR>          coverletter\n",
      "04/06/2025  09:38 PM            34,864 groq_api.ipynb\n",
      "04/06/2025  03:28 PM    <DIR>          imgs\n",
      "04/06/2025  05:19 PM             1,610 readme.md\n",
      "04/06/2025  05:19 PM               204 requirements.txt\n",
      "04/06/2025  09:19 PM    <DIR>          vectorstore\n",
      "               4 File(s)         39,976 bytes\n",
      "               8 Dir(s)  143,560,527,872 bytes free\n"
     ]
    }
   ],
   "source": [
    "cd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2dc3ed36-477b-433f-9bc3-be2ed02bff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Section</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summary</td>\n",
       "      <td>With 6 years of experience as a Data Scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKILLS</td>\n",
       "      <td>Programming Languages: Python, R, SQL, HTML/CS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE1</td>\n",
       "      <td>Consultant Product Owner | Deutsche Bank, Fran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE2</td>\n",
       "      <td>Data Scientist | Creditshelf AG, Frankfurt, Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE3</td>\n",
       "      <td>Data Scientist | FGFIS Global Services India L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE4</td>\n",
       "      <td>Associate Consultant | Capgemini Technology Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE5</td>\n",
       "      <td>Analyst | Axa Technology Services, Bengaluru, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PROFESSIONAL EXPERIENCE6</td>\n",
       "      <td>Junior Web Developer, Intern | Treat Well, Ben...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACADEMIC EDUCATION</td>\n",
       "      <td>Bachelor of Engineering – Electronics and Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACTIVITIES</td>\n",
       "      <td>Certified Open Water Diver, Padi Nov 2024\\nAwa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Section                                            Details\n",
       "0                   Summary  With 6 years of experience as a Data Scientist...\n",
       "1                    SKILLS  Programming Languages: Python, R, SQL, HTML/CS...\n",
       "2  PROFESSIONAL EXPERIENCE1  Consultant Product Owner | Deutsche Bank, Fran...\n",
       "3  PROFESSIONAL EXPERIENCE2  Data Scientist | Creditshelf AG, Frankfurt, Ge...\n",
       "4  PROFESSIONAL EXPERIENCE3  Data Scientist | FGFIS Global Services India L...\n",
       "5  PROFESSIONAL EXPERIENCE4  Associate Consultant | Capgemini Technology Se...\n",
       "6  PROFESSIONAL EXPERIENCE5  Analyst | Axa Technology Services, Bengaluru, ...\n",
       "7  PROFESSIONAL EXPERIENCE6  Junior Web Developer, Intern | Treat Well, Ben...\n",
       "8        ACADEMIC EDUCATION  Bachelor of Engineering – Electronics and Comm...\n",
       "9                ACTIVITIES  Certified Open Water Diver, Padi Nov 2024\\nAwa..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"./apps/resources/my_resume.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63c0f341-ccb4-4cbb-a95b-f57406e8995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Section\"],\n",
    "                       metadatas={\"details\": row[\"Details\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4ecf89bf-d4c1-402e-9157-77ec2796c6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('role', 'Product Owner: Product Data Management and Presentation'), ('experience', 'More than 3 years of experience in a Product role coming from a value- and customer-driven environment'), ('skills', ['Effective in communication, planning and good coordination skills', 'Good knowledge and proven experience in working with software development teams, preferably in agile frameworks like Scrum or Kanban', 'Fluent business communication in English. Ability to communicate in German is a plus but not required']), ('employment_type', 'Full-time'), ('location', 'Munich, Germany'), ('description', 'Join our vibrant team at JSMD, a proud member of the ProSiebenSat.1 Group, where we bring people together through unforgettable real-life experiences. As our Product Owner: Product Data Management and Presentation, you will play a crucial role in enhancing our digital product offerings. Your ability to manage and present product data will help us deliver impactful experiences to our customers.'), ('responsibilities', ['Own and optimize product data flows, including tools and services that empower internal stakeholders to efficiently manage our product portfolio', 'Understand our products and customers to continuously refine Product Detail Pages (PDPs) and ensure they are informative and inspiring while driving engagement and supporting key KPIs', 'Enable our Search & Filtering Team with the right product data to improve discoverability of our products and help customers easily find the experiences they seek', 'Collaborate with analysts, the UX/UI team, and stakeholders to turn key ideas into a prioritized, actionable, KPI-driven roadmap that delivers customer and business value']), ('tools', ['Google Analytics 4', 'Looker Studio', 'Power BI', 'Usercentrics', 'JIRA', 'Confluence', 'Miro', 'ClickUp', 'Slack', 'MS365', 'Figma', 'Overflow']), ('tech_stack', {'frontend': ['React', 'TypeScript', 'Node.js (Fastify)', 'Jest', 'React Testing Library'], 'backend': ['NestJS', 'PHP', 'PostgreSQL', 'Apache Kafka', 'AWS (Lambda@Edge, CloudFront)'], 'infrastructure': ['Docker', 'Kubernetes', 'AWS', 'Terraform', 'Helm', 'Istio', 'Datadog', 'CloudWatch']}), ('company', 'Jochen Schweizer mydays Holding GmbH'), ('industry', 'Leisure, Tourism, Culture & Sport')])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_res.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fdbb4cc2-761c-46a2-bad4-0c5366c52ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list=[]\n",
    "for key, value in json_res.items():\n",
    "    value = collection.query(query_texts=key, n_results=2).get('metadatas', [])\n",
    "    result_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5c2e016-bbcb-41d0-9707-5ce326b5a8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[{'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'},\n",
       "   {'details': 'Associate Consultant | Capgemini Technology Services Pvt. Ltd, Bengaluru, IN | Dec ’16 – Oct’ 19\\n1. Upskilling and Digital Transformation\\n•Developed the Decision Tree to find the most suitable training and send emailers to the employees to take the most relevant training for upskilling.\\n•Build and construct prototypes, proof of concepts and present to the business using Tableau visualization tool.\\n•Over 37% reduction in cost for the trainings and certifications estimated for the training data set.\\n•Accurately predicting the performance of the employee with a certain training using Personalized Analysis and estimating the ROI.\\n2. Service Ticket Classification\\n•Performing SVM classification of the Silva service tickets to categorize them into user and auto raised tickets.\\n•Performing Exploratory Data Analysis on incidents and tasks data to discover patters and outliers to automate the manual tasks using SCOM.\\n•83% classification accuracy on a training data set of 100,000 incidents summary.\\n•More than 40% of the time saving for routing the incidents across the team.\\n•Reduction in cost incurred due to longer downtime and Higher efficiency achieved.\\n3. Social Media Analytics\\n•Getting data from Social Media Platforms via APIs and Python Packages\\n•Scrapping data using Pythons Beautiful Soup and Newspaper packages.\\n•Performed data cleansing and Sentiment analysis using NLTK (Python)'}]],\n",
       " [[{'details': 'Consultant Product Owner | Deutsche Bank, Frankfurt, Germany | Feb 2024 —Present\\n• Spearheaded the Basel IV project, implementing flooring logic for the Full Standard Approach (FSA), ensuring alignment\\nwith global financial standards, and reducing operational risk.\\n• Designed and implemented methodologies for Leverage Exposure (LE), Expected Loss Shortfall, and High Quality Liquid\\nAssets.\\n• Defined and prioritized product road-maps, ensuring alignment with stakeholder needs and regulatory timelines.\\n• Collaborated with engineering, finance, and risk teams to deliver impactful solutions and Tableau dashboards. Applied\\nagile practices to deliver high-quality products and regulatory standards while meeting deadlines.'},\n",
       "   {'details': 'Data Scientist | Creditshelf AG, Frankfurt, Germany | Sep’21 – Oct 2023\\n1. Document Classifier | Data Modelling\\n•Leveraged machine learning techniques to implement OCR-based extraction for scanned and well-formatted PDF documents, reducing human effort in data extraction.\\n•Developed a qualitative classifier using the XGBoost algorithm to classify documents into predefined classes based on extracted text, achieving an accuracy of 86% (Classification Problem).\\n•Proof of concept (POC) on extraction methods like Apache Tika, AWS Textract and Google Tesseract to optimize performance and cost.\\n•Utilized GitHub Actions to deploy the machine learning model to AWS ECR instances and established CI/CD pipelines for seamless Docker deployments.\\n•Implemented secure endpoints using FastAPI, integrated with Ingress and Helm configurations in Kubernetes for efficient deployment.\\n•Implement Sonar Cloud Linting to eliminate bugs, vulnerabilities and ensure continuous code quality on GitHub version control repo.\\n2. Risk Modeling| Risk Analytics\\n•Conduct risk analysis on borrower companies using various key performance indicators (KPIs) to assess and evaluate their level of risk.\\n•Compare and analyze different probability of default (PD) and credit scores, to establish benchmarks and assess creditworthiness.\\n•Analyzing Data from sources like Creditreform and Kantwert, to detect potential fraud, significantly supporting the identification and mitigation of financial crime risk.\\n•Utilize survival analysis techniques, specifically Kaplan-Meier and Nelson-Aalen estimators, to test, validate risk model and predict expected defaults and loss given default (LGD), providing insights into the probability and timing of default events.\\n3. Leadership Roles: Scrum Master\\n•Oversee the effective implementation of the agile development methodology within the team, adhere to the principles and practices of Scrum.\\n•Facilitate daily standup meetings and bi-weekly Retro meetings to foster collaboration between Product Owners and the Development Team to remove any obstacles or barriers.\\n•Suggest architectural enhancements for the infrastructure and contribute to co-authoring architecture proposal documents.\\n4. Investor and Partner Dashboards | Data Visualization & Reporting\\n•Created interactive dashboards in Tableau to facilitate Investor and Partner Portfolio Management, providing comprehensive insights.\\n•Optimized SQL queries and established seamless data source connections to empower the analytics dashboard, ensuring efficient data retrieval and processing.\\n•Successfully migrated Tableau server from version 2021.4 to 2022.1, ensuring seamless transfer of data sources and dashboards.\\n•Produced detailed reference documents and reports for finalized projects, utilizing Confluence as a collaborative platform for knowledge sharing and documentation.'}]],\n",
       " [[{'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'},\n",
       "   {'details': 'Junior Web Developer, Intern | Treat Well, Bengaluru, IN | Dec ’14 – Jan ’15\\n1.Write well designed, testable, efficient python code by using best practices.\\n2.Creating website layout/user interfaces by using standard HTML/CSS practices.\\n3.Integrating data from various back-end services like GCP and SQL databases.'}]],\n",
       " [[{'details': 'Associate Consultant | Capgemini Technology Services Pvt. Ltd, Bengaluru, IN | Dec ’16 – Oct’ 19\\n1. Upskilling and Digital Transformation\\n•Developed the Decision Tree to find the most suitable training and send emailers to the employees to take the most relevant training for upskilling.\\n•Build and construct prototypes, proof of concepts and present to the business using Tableau visualization tool.\\n•Over 37% reduction in cost for the trainings and certifications estimated for the training data set.\\n•Accurately predicting the performance of the employee with a certain training using Personalized Analysis and estimating the ROI.\\n2. Service Ticket Classification\\n•Performing SVM classification of the Silva service tickets to categorize them into user and auto raised tickets.\\n•Performing Exploratory Data Analysis on incidents and tasks data to discover patters and outliers to automate the manual tasks using SCOM.\\n•83% classification accuracy on a training data set of 100,000 incidents summary.\\n•More than 40% of the time saving for routing the incidents across the team.\\n•Reduction in cost incurred due to longer downtime and Higher efficiency achieved.\\n3. Social Media Analytics\\n•Getting data from Social Media Platforms via APIs and Python Packages\\n•Scrapping data using Pythons Beautiful Soup and Newspaper packages.\\n•Performed data cleansing and Sentiment analysis using NLTK (Python)'},\n",
       "   {'details': 'Junior Web Developer, Intern | Treat Well, Bengaluru, IN | Dec ’14 – Jan ’15\\n1.Write well designed, testable, efficient python code by using best practices.\\n2.Creating website layout/user interfaces by using standard HTML/CSS practices.\\n3.Integrating data from various back-end services like GCP and SQL databases.'}]],\n",
       " [[{'details': 'Certified Open Water Diver, Padi Nov 2024\\nAwarded Merit for Business English Certificate Preliminary, Cambridge ESOL May 2013\\nPrime Minister’s Scholarship for Professional Degree Course, India Sep 2012 - Jun 2016\\nLanguage : English - Professional Proficiency German - Working Proficiency'},\n",
       "   {'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'}]],\n",
       " [[{'details': 'With 6 years of experience as a Data Scientist, I am highly passionate about utilizing artificial intelligence analytics and to address real-world business challenges. My primary emphasis is onutilizing machine learning methods to derive valuable insights and provide dependable solutionsin various sectors. I excel in converting stakeholder and technical demands into user-centeredbusiness solutions, aiming to create a significant influence in the field of data science.'},\n",
       "   {'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'}]],\n",
       " [[{'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'},\n",
       "   {'details': 'Certified Open Water Diver, Padi Nov 2024\\nAwarded Merit for Business English Certificate Preliminary, Cambridge ESOL May 2013\\nPrime Minister’s Scholarship for Professional Degree Course, India Sep 2012 - Jun 2016\\nLanguage : English - Professional Proficiency German - Working Proficiency'}]],\n",
       " [[{'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'},\n",
       "   {'details': 'Certified Open Water Diver, Padi Nov 2024\\nAwarded Merit for Business English Certificate Preliminary, Cambridge ESOL May 2013\\nPrime Minister’s Scholarship for Professional Degree Course, India Sep 2012 - Jun 2016\\nLanguage : English - Professional Proficiency German - Working Proficiency'}]],\n",
       " [[{'details': \"Data Scientist | FGFIS Global Services India LLP (Fossil Group), Bengaluru, IN | Nov ’19 – July’ 21\\n1. Channel Sales Analysis\\n•Develop business architecture using requirements such as scope, processes, alternatives, and risks.\\n•Understand business requirement, trends and generate business insights. Performed EDA on the data set to gather insights.\\n•Building and implementing ML models like Linear Regression (for Sales and Demand prediction), Times Series, RFM and Clustering along with storytelling through visualization in Tableau.\\n2. Sales Data Forecast including COVID Impact\\n•Exploring the E-commerce, Retail and Wholesale data for sales and finding patterns in the data using python.\\n•Running regression models to forecast future sales for all the portfolio brands and introducing COVID-19 impact in the models.\\n•Exporting datasets from Google cloud using Big Query for analysis.\\n3. Health Data Analysis and Classification\\n•Understanding User behavior based on their steps activity from smart watch data and classifying in different classes based on their goal completion statistics.\\n•Understanding user churn behavior based on their lifetime and activity analysis and predicting user churn and providing triggers to business team for user retention.\\nWith 6 years of experience as a Data Scientist, I am highly passionate about utilizing artificial intelligence analytics and to address real-world business challenges. My primary emphasis is onutilizing machine learning methods to derive valuable insights and provide dependable solutionsin various sectors. I excel in converting stakeholder and technical demands into user-centeredbusiness solutions, aiming to create a significant influence in the field of data science.\\n4. NLP Based Review Analysis\\n•Performing sentiment analysis on reviews and feedback data using NLP in python and visualization using Cloudword.\\n•Data cleaning and formatting in python using packages such as pandas, speedml, sklear\\n•Converting natural language questions to SQL/MDX queries using python's NLTK library.\"},\n",
       "   {'details': 'Programming Languages: Python, R, SQL, HTML/CSS\\nReporting Tools: Tableau, Power BI, SAS Visual Analytics\\nData Warehousing Tools: MySQL, Oracle DB, PostgreSQL, AWS S3, Google BigQuery, Apache Spark, Azure Databricks, AWS Athena, Apache Kafka, Dremio\\nStatistics and ML: CART, NLP, Clustering, Sentiment Analysis, Deep Learning, Time Series Analysis, AI, Langchain, Linear/Logistic Regression, Classification\\nCloud Environment: Amazon Web Services, Google Cloud Platform, Docker, Kubernets, Git\\nLibraries: TensorFlow, Keras, Spark MLlib, NLTK, Scikit-Learn, SciPy, Pandas, NumPy, Seaborn, TensorFlow, Plotly, Texthero'}]],\n",
       " [[{'details': 'Certified Open Water Diver, Padi Nov 2024\\nAwarded Merit for Business English Certificate Preliminary, Cambridge ESOL May 2013\\nPrime Minister’s Scholarship for Professional Degree Course, India Sep 2012 - Jun 2016\\nLanguage : English - Professional Proficiency German - Working Proficiency'},\n",
       "   {'details': \"Data Scientist | FGFIS Global Services India LLP (Fossil Group), Bengaluru, IN | Nov ’19 – July’ 21\\n1. Channel Sales Analysis\\n•Develop business architecture using requirements such as scope, processes, alternatives, and risks.\\n•Understand business requirement, trends and generate business insights. Performed EDA on the data set to gather insights.\\n•Building and implementing ML models like Linear Regression (for Sales and Demand prediction), Times Series, RFM and Clustering along with storytelling through visualization in Tableau.\\n2. Sales Data Forecast including COVID Impact\\n•Exploring the E-commerce, Retail and Wholesale data for sales and finding patterns in the data using python.\\n•Running regression models to forecast future sales for all the portfolio brands and introducing COVID-19 impact in the models.\\n•Exporting datasets from Google cloud using Big Query for analysis.\\n3. Health Data Analysis and Classification\\n•Understanding User behavior based on their steps activity from smart watch data and classifying in different classes based on their goal completion statistics.\\n•Understanding user churn behavior based on their lifetime and activity analysis and predicting user churn and providing triggers to business team for user retention.\\nWith 6 years of experience as a Data Scientist, I am highly passionate about utilizing artificial intelligence analytics and to address real-world business challenges. My primary emphasis is onutilizing machine learning methods to derive valuable insights and provide dependable solutionsin various sectors. I excel in converting stakeholder and technical demands into user-centeredbusiness solutions, aiming to create a significant influence in the field of data science.\\n4. NLP Based Review Analysis\\n•Performing sentiment analysis on reviews and feedback data using NLP in python and visualization using Cloudword.\\n•Data cleaning and formatting in python using packages such as pandas, speedml, sklear\\n•Converting natural language questions to SQL/MDX queries using python's NLTK library.\"}]],\n",
       " [[{'details': 'Junior Web Developer, Intern | Treat Well, Bengaluru, IN | Dec ’14 – Jan ’15\\n1.Write well designed, testable, efficient python code by using best practices.\\n2.Creating website layout/user interfaces by using standard HTML/CSS practices.\\n3.Integrating data from various back-end services like GCP and SQL databases.'},\n",
       "   {'details': \"Data Scientist | FGFIS Global Services India LLP (Fossil Group), Bengaluru, IN | Nov ’19 – July’ 21\\n1. Channel Sales Analysis\\n•Develop business architecture using requirements such as scope, processes, alternatives, and risks.\\n•Understand business requirement, trends and generate business insights. Performed EDA on the data set to gather insights.\\n•Building and implementing ML models like Linear Regression (for Sales and Demand prediction), Times Series, RFM and Clustering along with storytelling through visualization in Tableau.\\n2. Sales Data Forecast including COVID Impact\\n•Exploring the E-commerce, Retail and Wholesale data for sales and finding patterns in the data using python.\\n•Running regression models to forecast future sales for all the portfolio brands and introducing COVID-19 impact in the models.\\n•Exporting datasets from Google cloud using Big Query for analysis.\\n3. Health Data Analysis and Classification\\n•Understanding User behavior based on their steps activity from smart watch data and classifying in different classes based on their goal completion statistics.\\n•Understanding user churn behavior based on their lifetime and activity analysis and predicting user churn and providing triggers to business team for user retention.\\nWith 6 years of experience as a Data Scientist, I am highly passionate about utilizing artificial intelligence analytics and to address real-world business challenges. My primary emphasis is onutilizing machine learning methods to derive valuable insights and provide dependable solutionsin various sectors. I excel in converting stakeholder and technical demands into user-centeredbusiness solutions, aiming to create a significant influence in the field of data science.\\n4. NLP Based Review Analysis\\n•Performing sentiment analysis on reviews and feedback data using NLP in python and visualization using Cloudword.\\n•Data cleaning and formatting in python using packages such as pandas, speedml, sklear\\n•Converting natural language questions to SQL/MDX queries using python's NLTK library.\"}]]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b1192995-559f-4067-9455-a76ed4cc888e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Product Owner: Product Data Management and Presentation Role\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Product Owner: Product Data Management and Presentation role at Jochen Schweizer mydays Holding GmbH, as advertised. With over 8 years of experience in the industry as a Data Scientist, I am confident that my skills and expertise make me an ideal candidate for this position.\n",
      "\n",
      "As a seasoned data professional, I have a strong background in managing and presenting complex data to drive business decisions. My experience in working with cross-functional teams, including software development teams, has equipped me with the skills to effectively communicate and collaborate with stakeholders to deliver impactful results. I am well-versed in agile frameworks like Scrum and Kanban, which I believe will enable me to make a seamless transition into this role.\n",
      "\n",
      "In my previous role as an Associate Consultant at Capgemini Technology Services, I developed and implemented decision trees to identify the most suitable training for employees, resulting in a 37% reduction in training costs. I also built prototypes and presented business cases using Tableau visualization tools, demonstrating my ability to distill complex data into actionable insights. Additionally, I performed SVM classification of service tickets, achieving an accuracy of 83% on a training dataset of 100,000 incidents, which led to a significant reduction in manual tasks and improved efficiency.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to work with a wide range of tools and technologies, including Google Analytics 4, Looker Studio, Power BI, and JIRA. My expertise in programming languages such as Python, R, and SQL, as well as my experience with data warehousing tools like MySQL, Oracle DB, and PostgreSQL, will enable me to make a significant contribution to the team.\n",
      "\n",
      "As a data scientist, I am passionate about using data to drive business decisions and improve customer experiences. I am impressed by Jochen Schweizer mydays Holding GmbH's commitment to delivering unforgettable real-life experiences and believe that my skills and expertise align with the company's goals. I am excited about the opportunity to work in a vibrant team and contribute to the development of innovative digital product offerings.\n",
      "\n",
      "In terms of specific skills, I would like to highlight my proficiency in Python, which I believe is highly relevant to this role. My experience with Python has equipped me with the skills to develop and implement complex data models, perform data analysis, and create data visualizations. I am confident that my Python skills will enable me to make a significant contribution to the team and drive business results.\n",
      "\n",
      "Thank you for considering my application. I would welcome the opportunity to discuss my qualifications further and explain in greater detail why I am the ideal candidate for this role. Please do not hesitate to contact me if you require any additional information.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "XXX\n"
     ]
    }
   ],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "\n",
    "        ### INSTRUCTION:\n",
    "        You are XXX, a Data scientist with 8 years of industry experience in different domains of work. \n",
    "        You are applying for the job with the {job_description}.\n",
    "        Your job is to write an email to the recruiting manager of the job mentioned above describing your capability of fulfilling \n",
    "        their needs and your motivation to work fro the company. You can also give examples from the experience before to make it more \n",
    "        natural and effective. Also add the most relevant skill from the following skills to showcase your portfolio: {link_list}\n",
    "        Remember you are XXX, a data scientist.\n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(json_res), \"link_list\": result_list[0] })\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7d810-254f-406b-b345-138bf5fda10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287bc4cf-907d-4b93-88cb-154d84580f77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
